{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fe0f7066-0230-43ce-83b7-3b79b892db6c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# NATIONAL WEATHER SERVICE\n",
    "This Python script retrieves weather data from the National Weather Service (NWS) API to get hourly and weekly forecasts, which are updated every hour.\n",
    "\n",
    "**Fetch Data** ‚Üí The script sends a GET request to the NWS API using a specific location‚Äôs latitude and longitude.\n",
    "\n",
    "**Extract Forecasts** ‚Üí It retrieves hourly weather data (temperature, humidity, wind speed, etc.) and weekly weather forecasts.\n",
    "\n",
    "**Convert to Structured Format** ‚Üí The response is processed into a PySpark DataFrame.\n",
    "\n",
    "**Update Regularly** ‚Üí Since the NWS updates its forecasts every hour, the script is scheduled to run periodically to keep the data current.\n",
    "\n",
    "This approach automates weather data collection, making it useful for tracking real-time and future weather conditions. üå§Ô∏èüå°Ô∏è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6fa7ab87-e7a9-4237-8fdd-0713e267d37c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# IMPORT REQUIRED LIBRARIES\n",
    "import requests\n",
    "import time\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, BooleanType, DoubleType\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a7a97d5e-1792-4545-9c72-30da9a7538f1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## LET'S CREATE BRONZE TABLES\n",
    "THIS SECTION OF CODE USES NWS API TO ACQUIRE WEATHER DATA. IT CREATES TWO RAW DATA TABLES, ONE FOR HOURLY DATA AND ONE FOR THE WEEKLY FORECAST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0a1a294e-70a9-4fcf-b728-1a27a9358783",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# DEFINE SCHEMA\n",
    "period_schema = StructType([\n",
    "    StructField(\"number\", IntegerType(), True),\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"startTime\", StringType(), True),\n",
    "    StructField(\"endTime\", StringType(), True),\n",
    "    StructField(\"isDaytime\", BooleanType(), True),\n",
    "    StructField(\"temperature\", IntegerType(), True),\n",
    "    StructField(\"temperatureUnit\", StringType(), True),\n",
    "    StructField(\"windSpeed\", StringType(), True),\n",
    "    StructField(\"windDirection\", StringType(), True),\n",
    "    StructField(\"shortForecast\", StringType(), True),\n",
    "    StructField(\"detailedForecast\", StringType(), True)\n",
    "])\n",
    "\n",
    "def fetch_weather_data(api_url):\n",
    "    \"\"\"Fetch weather forecast data from NWS API and return it as a PySpark DataFrame.\"\"\"\n",
    "    try:\n",
    "        # Step 1: FETCH LOCATION METADATA\n",
    "        response = requests.get(api_url)\n",
    "        if response.status_code != 200:\n",
    "            print(f\"‚ùå Failed to fetch metadata. Status Code: {response.status_code}\")\n",
    "            return None\n",
    "\n",
    "        metadata = response.json()\n",
    "\n",
    "        # Step 2: EXTRACT\n",
    "        forecast_url = metadata.get(\"properties\", {}).get(\"forecast\")\n",
    "        if not forecast_url:\n",
    "            print(\"‚ö†Ô∏è No forecast URL found in metadata!\")\n",
    "            return None\n",
    "        \n",
    "        # Step 3: FETCH DATA\n",
    "        forecast_response = requests.get(forecast_url)\n",
    "        if forecast_response.status_code != 200:\n",
    "            print(f\"‚ùå Failed to fetch forecast data. Status Code: {forecast_response.status_code}\")\n",
    "            return None\n",
    "\n",
    "        forecast_data = forecast_response.json()\n",
    "\n",
    "        # Step 4: EXTRACT THE DATA\n",
    "        periods_data = forecast_data[\"properties\"].get(\"periods\", [])\n",
    "\n",
    "        if not periods_data:\n",
    "            print(\"‚ö†Ô∏è No forecast periods available!\")\n",
    "            return None\n",
    "\n",
    "        # Step 5: CONVERT TO PYSPARK DATAFRAME\n",
    "        df = spark.createDataFrame(periods_data, schema=period_schema)\n",
    "\n",
    "        print(f\"‚úÖ Successfully retrieved {df.count()} records!\")\n",
    "        return df\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error fetching data: {e}\")\n",
    "        return None\n",
    "\n",
    "# API ENDPOINT FOR DFW AIRPORT\n",
    "nws_url = \"https://api.weather.gov/points/32.896,-97.037\"\n",
    "\n",
    "# FETCH WEATHER DATA\n",
    "weather_df = fetch_weather_data(nws_url)\n",
    "\n",
    "# ADD A TIMESTAMP TABLE\n",
    "weather_df = weather_df.withColumn(\"uploaded_timestamp\", current_timestamp())\n",
    "\n",
    "# WRITE THE WEEKLY DATA TO THE BRONZE TABLE\n",
    "weather_df.write.mode(\"overwrite\").saveAsTable(\"tabular.dataexpert.josephgabbrielle62095_nws_dfw_weekly_bronze\")\n",
    "display(weather_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6b5e9932-c6b3-4503-83b9-fe72dfaa40f4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### LET'S CREATE THE NWS HOURLY BRONZE TABLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9fed32ed-1425-4a13-ad87-7da7903a6964",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# DEFINE SCHEMA\n",
    "hourly_period_schema = StructType([\n",
    "    StructField(\"number\", IntegerType(), True),\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"startTime\", StringType(), True),\n",
    "    StructField(\"endTime\", StringType(), True),\n",
    "    StructField(\"isDaytime\", BooleanType(), True),\n",
    "    StructField(\"temperature\", IntegerType(), True),\n",
    "    StructField(\"temperatureUnit\", StringType(), True),\n",
    "    StructField(\"windSpeed\", StringType(), True),\n",
    "    StructField(\"windDirection\", StringType(), True),\n",
    "    StructField(\"shortForecast\", StringType(), True),\n",
    "    StructField(\"detailedForecast\", StringType(), True)\n",
    "])\n",
    "\n",
    "def fetch_hourly_weather_data(api_url):\n",
    "    \"\"\"Fetch hourly weather forecast data from NWS API and return it as a PySpark DataFrame.\"\"\"\n",
    "    try:\n",
    "        # FETCH FORECAST DATA\n",
    "        response = requests.get(api_url)\n",
    "        if response.status_code != 200:\n",
    "            print(f\"‚ùå Failed to fetch forecast data. Status Code: {response.status_code}\")\n",
    "            return None\n",
    "\n",
    "        forecast_data = response.json()\n",
    "\n",
    "        # EXTRACT PERIOD DATA\n",
    "        periods_data = forecast_data[\"properties\"].get(\"periods\", [])\n",
    "\n",
    "        if not periods_data:\n",
    "            print(\"‚ö†Ô∏è No forecast periods available!\")\n",
    "            return None\n",
    "\n",
    "        # CONVERT TO PYSPARK DATAFRAME\n",
    "        df = spark.createDataFrame(periods_data, schema=hourly_period_schema)\n",
    "\n",
    "        print(f\"‚úÖ Successfully retrieved {df.count()} hourly forecast records!\")\n",
    "        return df\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error fetching data: {e}\")\n",
    "        return None\n",
    "\n",
    "# API ENDPOINT FOR DFW AIRPORT\n",
    "nws_hourly_url = \"https://api.weather.gov/gridpoints/FWD/80,109/forecast/hourly\"\n",
    "\n",
    "# FETCH FORECAST DATA\n",
    "hourly_weather_df = fetch_hourly_weather_data(nws_hourly_url)\n",
    "\n",
    "hourly_weather_df = hourly_weather_df.withColumn(\"uploaded_timestamp\", current_timestamp())\n",
    "\n",
    "# WRITE DATA TO THE HOURLY BRONZE TABLE\n",
    "hourly_weather_df.write.mode(\"overwrite\").saveAsTable(\"tabular.dataexpert.josephgabbrielle62095_nws_dfw_hourly_bronze\")\n",
    "display(hourly_weather_df)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "aviation_nws_bronze",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
