{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e79cdfd3-ac83-4a7d-8789-ba28c5e8e741",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# NATIONAL WEATHER SERVICE HOURLY SILVER TABLE\n",
    "This Python script relies on the NWS Bronze task to run. Once that runs, this script cleans the data and performs a unit test. If the unit test is passed, then the table is written to the gold table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8c1008c8-7125-48bc-a2b3-338603ae8492",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# IMPORT REQUIRED LIBRARIES\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6f78906f-3cda-4d4e-8207-77f0dd301554",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## LET'S CLEAN THE DATA\n",
    "TO GET THE NWS HOURLY DATA INTO A USEABLE FORMAT, THE DATA MUST BE IMPROVED BY CHANGING THE DATA TYPES AND THE COLUMN NAMES. THIS STEP WILL EXCLUDE ANY UNNEEDED DATA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e3254c4f-ae37-4660-8bb7-154b077bd0d2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# CREATE THE DATAFRAME FROM THE BRONZE TABLE\n",
    "hourly_bronze = spark.sql(\"SELECT * FROM tabular.dataexpert.josephgabbrielle62095_nws_dfw_hourly_bronze\")\n",
    "display(hourly_bronze)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "55e5beb4-68fd-4db6-9d84-a2c13561612d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# CHANGE THE DATE TYPE TO TIMESTAMP\n",
    "hourly_bronze = hourly_bronze.withColumn(\"startTime\", col(\"startTime\").cast(TimestampType())).withColumn(\"endTime\", col(\"endTime\").cast(TimestampType()))\n",
    "\n",
    "# CHANGE COLUMN FORMATTING TO UPPERCASE\n",
    "hourly_bronze = hourly_bronze.withColumn(\"isDaytime\", upper(col(\"isDaytime\"))).withColumn(\"windSpeed\", upper(col(\"windSpeed\"))).withColumn(\"shortForecast\", upper(col(\"shortForecast\")))\n",
    "\n",
    "# RENAME COLUMNS\n",
    "hourly_bronze = hourly_bronze \\\n",
    "                .select(\n",
    "                    hourly_bronze['startTime'].alias('start_time'),\n",
    "                    hourly_bronze['endTime'].alias('end_time'),\n",
    "                    hourly_bronze['isDaytime'].alias('is_daytime'),\n",
    "                    hourly_bronze['temperature'],\n",
    "                    hourly_bronze['temperatureUnit'].alias('temperature_unit'),\n",
    "                    hourly_bronze['windSpeed'].alias('wind_speed'),\n",
    "                    hourly_bronze['windDirection'].alias('wind_direction'),\n",
    "                    hourly_bronze['shortForecast'].alias('short_forecast'),\n",
    "                    hourly_bronze['uploaded_timestamp']\n",
    "                )\n",
    "\n",
    "# CREATE THE SILVER TABLE\n",
    "hourly_bronze.write.mode(\"overwrite\").saveAsTable(\"tabular.dataexpert.josephgabbrielle62095_nws_dfw_hourly_silver\")\n",
    "\n",
    "display(hourly_bronze)\n",
    "hourly_bronze.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ca85f9bf-8078-4691-a1b5-46f5b9f5d9d9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## LET'S PERFORM THE UNIT TESTS\n",
    "BY PERFORMING UNIT TESTS, END USERS CAN BE SURE OF THE QUALITY OF THE DATA. THIS WILL AVOID PUTTING INCORRECT OR WRONG DATA INTO PRODUCTION."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2de93db7-336d-4d63-8edc-7641b5f78910",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# QUERY THE TABLE\n",
    "hourly_silver = spark.sql(\"SELECT * FROM tabular.dataexpert.josephgabbrielle62095_nws_dfw_hourly_silver\")\n",
    "\n",
    "# PRE-DEFINED COLUMN NAMES\n",
    "hourly_columns = [\"start_time\", \"end_time\", \"is_daytime\", \"temperature\", \"temperature_unit\", \"wind_speed\", \"wind_direction\", \"short_forecast\", \"uploaded_timestamp\"]\n",
    "\n",
    "# CHECK THAT EVERY COLUMN EXISTS\n",
    "for i in hourly_columns:\n",
    "    if i in hourly_silver.columns:\n",
    "        print(\"Column exists in DataFrame\")\n",
    "    else:\n",
    "        raise ValueError(\"There is a missing column!\")\n",
    "\n",
    "# CHECK THAT DATA IS FOUND\n",
    "if hourly_silver.count() > 1:\n",
    "    print(\"Data found\")\n",
    "else:\n",
    "    raise ValueError(\"There is no data!\")\n",
    "\n",
    "# ENSURE THAT NO NULLS EXIST\n",
    "if hourly_silver.filter(col(\"start_time\").isNull()).limit(1).count() > 0:  \n",
    "    raise ValueError(\"There is a null in the start_time column!\")\n",
    "elif hourly_silver.filter(col(\"end_time\").isNull()).limit(1).count() > 0:  \n",
    "    raise ValueError(\"There is a null in the end_time column!\")\n",
    "elif hourly_silver.filter(col(\"is_daytime\").isNull()).limit(1).count() > 0:  \n",
    "    raise ValueError(\"There is a null in the is_daytime column!\")\n",
    "elif hourly_silver.filter(col(\"temperature\").isNull()).limit(1).count() > 0:  \n",
    "    raise ValueError(\"There is a null in the temperature column!\")\n",
    "elif hourly_silver.filter(col(\"temperature_unit\").isNull()).limit(1).count() > 0:  \n",
    "    raise ValueError(\"There is a null in the temperature_unit column!\")\n",
    "elif hourly_silver.filter(col(\"wind_speed\").isNull()).limit(1).count() > 0:  \n",
    "    raise ValueError(\"There is a null in the wind_speed column!\")\n",
    "elif hourly_silver.filter(col(\"wind_direction\").isNull()).limit(1).count() > 0:  \n",
    "    raise ValueError(\"There is a null in the wind_direction column!\")\n",
    "elif hourly_silver.filter(col(\"short_forecast\").isNull()).limit(1).count() > 0:  \n",
    "    raise ValueError(\"There is a null in the short_forecast column!\")\n",
    "elif hourly_silver.filter(col(\"uploaded_timestamp\").isNull()).limit(1).count() > 0:  \n",
    "    raise ValueError(\"There is a null in the uploaded_timestamp column!\")\n",
    "else:\n",
    "    print(\"No nulls found in the dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "efb455fb-fdaf-4e28-a5ce-15ce596b326c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## GOLD TABLES\n",
    "IF THE DATA PASSES THE UNIT TESTS, THEN THE DATA CAN BE WRITTEN INTO THE GOLD TABLE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "15999f28-6ea1-4466-871b-094b919afab3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# WRITE TO THE DATABASE\n",
    "hourly_silver.write.mode(\"overwrite\").saveAsTable(\"tabular.dataexpert.josephgabbrielle62095_nws_dfw_hourly_gold\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 6368848666127082,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "aviation_nws_silver_hourly",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
