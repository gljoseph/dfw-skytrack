{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a7ae4020-2698-49ab-93e5-58d58e525220",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# NATIONAL WEATHER SERVICE WEEKLY SILVER TABLE\n",
    "This Python script relies on the NWS Bronze task to run. Once that runs, this script cleans the data and performs a unit test. If the unit test is passed, then the table is written to the gold table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8c1008c8-7125-48bc-a2b3-338603ae8492",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# IMPORT NECESSARY LIBRARIES\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4337ec80-980d-4a67-8bec-3b028cbaf068",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## LET'S CLEAN THE DATA\n",
    "TO GET THE NWS WEEKLY DATA INTO A USEABLE FORMAT, THE DATA MUST BE IMPROVED BY CHANGING THE DATA TYPES AND THE COLUMN NAMES. THIS STEP WILL EXCLUDE ANY UNNEEDED DATA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b473f348-f344-4364-b477-049966bd6dd2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# QUERY THE WEEKLY BRONZE TABLE\n",
    "weekly_bronze = spark.sql(\"SELECT * FROM tabular.dataexpert.josephgabbrielle62095_nws_dfw_weekly_bronze\")\n",
    "\n",
    "# CHANGE DATA TYPE\n",
    "weekly_bronze = weekly_bronze.withColumn(\"startTime\", col(\"startTime\").cast(TimestampType())).withColumn(\"endTime\", col(\"endTime\").cast(TimestampType()))\n",
    "\n",
    "# UPDATE FORMATTING SO COLUMNS ARE UPPERCASE\n",
    "weekly_bronze = weekly_bronze.withColumn(\"name\", upper(col(\"name\"))).withColumn(\"isDaytime\", upper(col(\"isDaytime\"))).withColumn(\"windSpeed\", upper(col(\"windSpeed\"))).withColumn(\"shortForecast\", upper(col(\"shortForecast\"))).withColumn(\"detailedForecast\", upper(col(\"detailedForecast\")))\n",
    "\n",
    "# RENAME COLUMN NAMES\n",
    "weekly_bronze = weekly_bronze \\\n",
    "                .select(\n",
    "                    weekly_bronze['name'],\n",
    "                    weekly_bronze['startTime'].alias('start_time'),\n",
    "                    weekly_bronze['endTime'].alias('end_time'),\n",
    "                    weekly_bronze['isDaytime'].alias('is_daytime'),\n",
    "                    weekly_bronze['temperature'],\n",
    "                    weekly_bronze['temperatureUnit'].alias('temperature_unit'),\n",
    "                    weekly_bronze['windSpeed'].alias('wind_speed'),\n",
    "                    weekly_bronze['windDirection'].alias('wind_direction'),\n",
    "                    weekly_bronze['shortForecast'].alias('short_forecast'),\n",
    "                    weekly_bronze['detailedForecast'].alias('detailed_forecast')\n",
    "                )\n",
    "\n",
    "# CREATE THE SILVER TABLE\n",
    "weekly_bronze.write.mode(\"overwrite\").saveAsTable(\"tabular.dataexpert.josephgabbrielle62095_nws_dfw_weekly_silver\")\n",
    "\n",
    "display(weekly_bronze)\n",
    "weekly_bronze.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "56061c91-f5e3-4cbd-b6d5-814626b9f2f3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## LET'S PERFORM THE UNIT TESTS\n",
    "BY PERFORMING UNIT TESTS, END USERS CAN BE SURE OF THE QUALITY OF THE DATA. THIS WILL AVOID PUTTING INCORRECT OR WRONG DATA INTO PRODUCTION."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6d007495-64e4-44e9-befb-f93a82db1dc8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# QUERY THE SILVER TABLE\n",
    "weekly_silver = spark.sql(\"SELECT * FROM tabular.dataexpert.josephgabbrielle62095_nws_dfw_weekly_silver\")\n",
    "\n",
    "# THESE ARE THE PRE-DETERMINED COLUMN NAMES\n",
    "weekly_columns = [\"name\", \"start_time\", \"end_time\", \"is_daytime\", \"temperature\", \"temperature_unit\", \"wind_speed\", \"wind_direction\", \"short_forecast\", \"detailed_forecast\"]\n",
    "\n",
    "# CHECK THAT THE REQUIRED COLUMNS EXIST\n",
    "for i in weekly_columns:\n",
    "    if i in weekly_silver.columns:\n",
    "        print(\"Column exists in DataFrame\")\n",
    "    else:\n",
    "        raise ValueError(\"There is a missing column!\")\n",
    "\n",
    "# CHECK THAT THERE IS DATA\n",
    "if weekly_silver.count() > 1:\n",
    "    print(\"Data found\")\n",
    "else:\n",
    "    raise ValueError(\"There is no data!\")\n",
    "\n",
    "# CHECK THAT THE COLUMNS HAVE DATA\n",
    "if weekly_silver.filter(col(\"name\").isNull()).limit(1).count() > 0: \n",
    "    raise ValueError(\"There is a null in the name column!\")\n",
    "elif weekly_silver.filter(col(\"start_time\").isNull()).limit(1).count() > 0:  \n",
    "    raise ValueError(\"There is a null in the start_time column!\")\n",
    "elif weekly_silver.filter(col(\"end_time\").isNull()).limit(1).count() > 0:  \n",
    "    raise ValueError(\"There is a null in the end_time column!\")\n",
    "elif weekly_silver.filter(col(\"is_daytime\").isNull()).limit(1).count() > 0:  \n",
    "    raise ValueError(\"There is a null in the is_daytime column!\")\n",
    "elif weekly_silver.filter(col(\"temperature\").isNull()).limit(1).count() > 0:  \n",
    "    raise ValueError(\"There is a null in the temperature column!\")\n",
    "elif weekly_silver.filter(col(\"temperature_unit\").isNull()).limit(1).count() > 0:  \n",
    "    raise ValueError(\"There is a null in the temperature_unit column!\")\n",
    "elif weekly_silver.filter(col(\"wind_speed\").isNull()).limit(1).count() > 0:  \n",
    "    raise ValueError(\"There is a null in the wind_speed column!\")\n",
    "elif weekly_silver.filter(col(\"wind_direction\").isNull()).limit(1).count() > 0: \n",
    "    raise ValueError(\"There is a null in the wind_direction column!\")\n",
    "elif weekly_silver.filter(col(\"short_forecast\").isNull()).limit(1).count() > 0:  \n",
    "    raise ValueError(\"There is a null in the short_forecast column!\")\n",
    "elif weekly_silver.filter(col(\"detailed_forecast\").isNull()).limit(1).count() > 0: \n",
    "    raise ValueError(\"There is a null in the detailed_forecast column!\")\n",
    "else:\n",
    "    print(\"No nulls found in the dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "92752b41-075b-407a-ab1b-12fa22ee12cc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## GOLD TABLES\n",
    "IF THE DATA PASSES THE UNIT TESTS, THEN THE DATA CAN BE WRITTEN INTO THE GOLD TABLE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5eb44e7b-66f1-41e1-a4fb-0c2200526506",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# WRITE TO DATABASE\n",
    "weekly_silver.write.mode(\"overwrite\").saveAsTable(\"tabular.dataexpert.josephgabbrielle62095_nws_dfw_weekly_gold\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "aviation_nws_silver_weekly",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
